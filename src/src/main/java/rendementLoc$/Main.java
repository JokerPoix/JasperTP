package rendementLoc$;

import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import java.nio.file.Files;
import java.nio.file.Paths;
import org.apache.spark.sql.functions;

import rendementLoc$.DataLoader;


public class Main {
	public static void main(String[] args) {
	
	// Initialisation de Spark
    SparkSession spark = SparkSession.builder()
            .appName("rendementLoc$")
            .config("spark.master", "local[*]")  // Utilisation de tous les c≈ìurs CPU disponibles
            .config("spark.driver.memory", "16g")  // Augmenter la m√©moire allou√©e au driver
            .config("spark.executor.memory", "8g")  // Ajouter de la m√©moire aux ex√©cutors
            .config("spark.executor.cores", "4")  // Augmenter les c≈ìurs d'ex√©cution
            .config("spark.sql.shuffle.partitions", "16")  // Augmenter les partitions pour √©viter la saturation de m√©moire
            .getOrCreate();
    
    // D√©finition des chemins de fichiers
    String inputEstimationLoyerPath = "src/main/resources/inputs/EstimationLoyer";
    String inputValeursFoncieresPath = "src/main/resources/inputs/ValeursFoncieres";
    String outputFolderPath = "src/main/resources/outputs";
    String parquetEstimationLoyerFilePath = outputFolderPath + "/esmationLoyer.parquet";;
    String parquetValeursFoncieresFilePath = outputFolderPath + "/valeursFoncieres.parquet";;

    
    Dataset<Row> data;
    
    // üîÑ Fusion des fichiers EstimationLoyer (si non d√©j√† g√©n√©r√©)
    if (!Files.exists(Paths.get(outputFolderPath + "/estimationLoyer.csv"))) {
        Dataset<Row> estimationLoyerDF = DataAggregator.mergeCSVFromFolder(spark, inputEstimationLoyerPath);
        DataAggregator.saveAsCSV(estimationLoyerDF, outputFolderPath, "estimationLoyer.csv");
    } else {
        System.out.println("‚úÖ estimationLoyer.csv existe d√©j√†, pas de traitement.");
    }

    // üîÑ Conversion et fusion des fichiers txt (Valeurs Foncieres)
    if (!Files.exists(Paths.get(outputFolderPath + "/valeursFoncieres.csv"))) {
        Dataset<Row> valeursFoncieresDF = DataAggregator.convertAndMergeTXTtoCSV(spark, inputValeursFoncieresPath);
        DataAggregator.saveAsCSV(valeursFoncieresDF, outputFolderPath, "valeursFoncieres.csv");
    } else {
        System.out.println("‚úÖ valeursFoncieres.csv existe d√©j√†, pas de traitement.");
    }



    
}
}
